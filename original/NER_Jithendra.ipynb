{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06de50f6-7d5f-4cb0-8749-6ff8655ebfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180c834e-009f-4fd0-91dc-3f8e707d0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_text(path):\n",
    "    ''''\n",
    "    A function that preprocesses the text and returns text with labels\n",
    "    '''\n",
    "    df = pd.read_csv(path)\n",
    "    df.head()\n",
    "    text = df['sentence'] \n",
    "    t = []\n",
    "    for i in text:\n",
    "        t.append(i.lower().split())\n",
    "    label = df['tags']\n",
    "    l=[]\n",
    "    for i in label:\n",
    "        l.append(i.split())\n",
    "    return t,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0dd2e9-042a-45b4-9df1-4f1bf05eb1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length TRAIN\n",
      " Text: 38367 \t Label: 38367\n",
      "Length val\n",
      " Text: 4796 \t Label: 4796\n"
     ]
    }
   ],
   "source": [
    "train_text,train_label =get_label_text(\"ner_train.csv\")\n",
    "val_text,val_label =get_label_text(\"ner_val.csv\")\n",
    "print(\"Length TRAIN\\n Text:\",len(train_text),\"\\t\",\"Label:\",len(train_label))\n",
    "print(\"Length val\\n Text:\",len(val_text),\"\\t\",\"Label:\",len(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf15370-5cce-4144-ba1f-34b780377180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "seed = 7777\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca1900a-e374-4fbd-8006-e1bc8f449744",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = list(sorted(set(w for s in train_label for w in s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca2252b-96e3-4f04-96da-f6fc58b629f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38096534-a8f8-4350-8640-538280c340e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_ix = {t: i for i, t in enumerate(set(tag))}\n",
    "ner_tags_numerical = [tag_to_ix[t] for t in tag]\n",
    "\n",
    "ner_tags_onehot = torch.nn.functional.one_hot(torch.tensor(ner_tags_numerical))\n",
    "\n",
    "print(ner_tags_onehot)\n",
    "len(ner_tags_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befbfb15-8048-4595-b89a-a05699ad84da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art': 0,\n",
       " 'B-eve': 1,\n",
       " 'B-geo': 2,\n",
       " 'B-gpe': 3,\n",
       " 'B-nat': 4,\n",
       " 'B-org': 5,\n",
       " 'B-per': 6,\n",
       " 'B-tim': 7,\n",
       " 'I-art': 8,\n",
       " 'I-eve': 9,\n",
       " 'I-geo': 10,\n",
       " 'I-gpe': 11,\n",
       " 'I-nat': 12,\n",
       " 'I-org': 13,\n",
       " 'I-per': 14,\n",
       " 'I-tim': 15,\n",
       " 'O': 16}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map ={}\n",
    "j=0\n",
    "for i in tag:\n",
    "    # label_map[i] = ner_tags_onehot[j]\n",
    "    label_map[i] = j\n",
    "    j+=1\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a954105-5ec8-4ffa-8fbf-03b2bfd5cd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 1: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " 3: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 4: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 5: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 6: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 7: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " 8: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " 9: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " 10: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " 11: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 12: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " 13: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " 14: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " 15: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 16: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_map ={}\n",
    "j=0\n",
    "for i in tag:\n",
    "    # label_map[i] = ner_tags_onehot[j]\n",
    "    onehot_map[label_map[i]] = ner_tags_onehot[j].tolist()\n",
    "    j+=1\n",
    "onehot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a4d4c8-fea3-4f20-a92f-831491a29115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cls = len(label_map)\n",
    "num_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b51458-45ec-470b-be5d-989e7a00c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[[label_map[word] for word in sentence] for sentence in train_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18aed7fa-cbda-46c0-bb7c-42e30da91248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38367,\n",
       " [3,\n",
       "  5,\n",
       "  13,\n",
       "  16,\n",
       "  6,\n",
       "  14,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  7,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  5,\n",
       "  13,\n",
       "  13,\n",
       "  16,\n",
       "  2,\n",
       "  10,\n",
       "  16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "014ad5a1-0170-4cbb-aa75-423b3457f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4796, [2, 16, 16, 16, 16, 16, 16, 5, 16, 16, 16, 16, 16, 16, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val=[[label_map[word] for word in sentence] for sentence in val_label]\n",
    "len(y_val),y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c2f6fa1-70eb-49ca-8667-850d39320956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29078\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(w for s in train_text for w in s )\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3852491d-4278-4222-ae45-b411b8617887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the unknown token to our vocabulary\n",
    "vocabulary.add(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "220d58e5-93ea-47a9-ab54-88d2cd35c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<pad>', 'cuban', 'national', 'assembly', 'speaker', 'ricardo', 'alarcon', 'made', 'the', 'comment', 'friday', 'in', 'a', 'speech', 'before', 'the', 'un', 'world', 'summit', 'in', 'new', 'york', '.', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "# Add the <pad> token to our vocabulary\n",
    "vocabulary.add(\"<pad>\")\n",
    "\n",
    "# Function that pads the given sentence\n",
    "# We are introducing this function here as an example\n",
    "# We will be utilizing it later in the tutorial\n",
    "def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "  window = [pad_token] * window_size\n",
    "  return window + sentence + window\n",
    "\n",
    "# Show padding example\n",
    "window_size = 2\n",
    "print(pad_window(train_text[0], window_size=window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb584795-4882-4ffb-98c7-4f81bcbc6faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29080"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are just converting our vocabularly to a list to be able to index into it\n",
    "# Sorting is not necessary, we sort to show an ordered word_to_ind dictionary\n",
    "# That being said, we will see that having the index for the padding token\n",
    "# be 0 is convenient as some PyTorch functions use it as a default value\n",
    "# such as nn.utils.rnn.pad_sequence, which we will cover in a bit\n",
    "ix_to_word = sorted(list(vocabulary))\n",
    "\n",
    "# Creating a dictionary to find the index of a given word\n",
    "word_to_ix = {word: ind for ind, word in enumerate(ix_to_word)}\n",
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1187e4-dcec-4826-9cc3-7c9ae3024810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1807"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aac182d8-d26f-441f-bfa7-076e10de6c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence is: ['we', 'always', 'come', 'to', 'kuwait']\n",
      "Going from words to indices: [28284, 2879, 6623, 26496, 15271]\n",
      "Going from indices to words: ['we', 'always', 'come', 'to', 'kuwait']\n"
     ]
    }
   ],
   "source": [
    "# Given a sentence of tokens, return the corresponding indices\n",
    "def convert_token_to_indices(sentence, word_to_ix):\n",
    "  indices = []\n",
    "  for token in sentence:\n",
    "    # Check if the token is in our vocabularly. If it is, get it's index.\n",
    "    # If not, get the index for the unknown token.\n",
    "    if token in word_to_ix:\n",
    "      index = word_to_ix[token]\n",
    "    else:\n",
    "      index = word_to_ix[\"<unk>\"]\n",
    "    indices.append(index)\n",
    "  return indices\n",
    "\n",
    "# More compact version of the same function\n",
    "def _convert_token_to_indices(sentence, word_to_ix):\n",
    "  return [word_to_ind.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "# Show an example\n",
    "example_sentence = [\"we\", \"always\", \"come\", \"to\", \"kuwait\"]\n",
    "example_indices = convert_token_to_indices(example_sentence, word_to_ix)\n",
    "restored_example = [ix_to_word[ind] for ind in example_indices]\n",
    "\n",
    "print(f\"Original sentence is: {example_sentence}\")\n",
    "print(f\"Going from words to indices: {example_indices}\")\n",
    "print(f\"Going from indices to words: {restored_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e88752b-3e4e-40d7-acf9-80f4a03558d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38367"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting our sentences to indices\n",
    "example_padded_indices = [convert_token_to_indices(s, word_to_ix) for s in train_text]\n",
    "len(example_padded_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "001b92e5-0898-44e2-93de-ed2eeda4addf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.6855, -1.2433,  0.6503,  1.7461, -1.5691],\n",
       "         [-1.0888, -0.2956,  0.0582, -1.5052,  1.0458],\n",
       "         [ 0.3358, -0.8030, -1.0766, -0.5173, -0.4558],\n",
       "         ...,\n",
       "         [ 0.0589,  1.7237,  1.7490, -1.0582, -0.8675],\n",
       "         [ 0.4299, -0.4685, -1.3853,  0.8946,  0.4812],\n",
       "         [ 1.3386, -0.0579,  1.6486, -1.9482, -1.3272]], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an embedding table for our words\n",
    "embedding_dim = 5\n",
    "embeds = nn.Embedding(len(vocabulary), embedding_dim)\n",
    "\n",
    "# Printing the parameters in our embedding table\n",
    "list(embeds.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "991e1656-0c1b-4cdc-b4e2-bc8f3cfe0f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3797,  0.6432, -1.1015, -0.4927,  2.3796],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the word Paris\n",
    "index = word_to_ix[\"delhi\"]\n",
    "index_tensor = torch.tensor(index, dtype=torch.long)\n",
    "paris_embed = embeds(index_tensor)\n",
    "paris_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac035507-5e2d-43cc-8107-57bdcb1e8318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3797,  0.6432, -1.1015, -0.4927,  2.3796],\n",
       "        [-1.8665, -1.9956, -2.5430,  0.5626, -0.8039]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get multiple embeddings at once\n",
    "index_paris = word_to_ix[\"delhi\"]\n",
    "index_ankara = word_to_ix[\"ankara\"]\n",
    "indices = [index_paris, index_ankara]\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long)\n",
    "embeddings = embeds(indices_tensor)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f8c8d2-9d8d-4b76-8d2e-601ef59480b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "def custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # Break our batch into the training examples (x) and labels (y)\n",
    "  # We are turning our x and y into tensors because nn.utils.rnn.pad_sequence\n",
    "  # method expects tensors. This is also useful since our model will be\n",
    "  # expecting tensor inputs.\n",
    "  x, y = zip(*batch)\n",
    "\n",
    "  # Now we need to window pad our training examples. We have already defined a\n",
    "  # function to handle window padding. We are including it here again so that\n",
    "  # everything is in one place.\n",
    "  def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "    window = [pad_token] * window_size\n",
    "    return window + sentence + window\n",
    "\n",
    "  # Pad the train examples.\n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "\n",
    "  # Now we need to turn words in our training examples to indices. We are\n",
    "  # copying the function defined earlier for the same reason as above.\n",
    "  def convert_tokens_to_indices(sentence, word_to_ix):\n",
    "    return [word_to_ix.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "  # Convert the train examples into indices.\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # We will now pad the examples so that the lengths of all the example in\n",
    "  # one batch are the same, making it possible to do matrix operations.\n",
    "  # We set the batch_first parameter to True so that the returned matrix has\n",
    "  # the batch as the first dimension.\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "\n",
    "  # pad_sequence function expects the input to be a tensor, so we turn x into one\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # We will also pad the labels. Before doing so, we will record the number\n",
    "  # of labels so that we know how many words existed in each example.\n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = torch.LongTensor(lengths)\n",
    "\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "  y_padded=torch.tensor([[onehot_map[int(word)] for word in sentence] for sentence in y_padded])\n",
    "  # We are now ready to return our variables. The order we return our variables\n",
    "  # here will match the order we read them in our training loop.\n",
    "  return x_padded, y_padded, lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74ee486a-5655-48a1-8a17-d44d466767ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # Prepare the datapoints\n",
    "  x, y = zip(*batch)\n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # Pad x so that all the examples in the batch have the same size\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # Pad y and record the length\n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = torch.LongTensor(lengths)\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "  y_padded=torch.tensor([[onehot_map[word] for word in sentence] for sentence in y_padded])\n",
    "  return x_padded, y_padded, lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66ee0afb-d10c-46b7-8bbd-e6f80d7c71ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Batched Input:\n",
      "tensor([[ 1807,  1807,  2998,  ...,  1807,  1807,  1807],\n",
      "        [ 1807,  1807,  3008,  ...,  1807,  1807,  1807],\n",
      "        [ 1807,  1807, 26220,  ...,  1807,  1807,  1807],\n",
      "        ...,\n",
      "        [ 1807,  1807, 26220,  ...,  1807,  1807,  1807],\n",
      "        [ 1807,  1807, 28177,  ...,  1807,  1807,  1807],\n",
      "        [ 1807,  1807, 10963,  ...,  1807,  1807,  1807]])\n",
      "Batched Labels:\n",
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]])\n",
      "Batched Lengths:\n",
      "tensor([21, 22, 20, 11, 21, 12, 38, 31, 13, 28, 24, 34, 34, 12, 13, 49, 28, 24,\n",
      "        25, 18, 14, 20, 16,  8, 45, 28, 19, 25, 32, 17, 24, 24, 13, 17, 27, 32,\n",
      "        20, 20, 20, 30, 28, 23, 25, 24, 16,  9, 23, 28, 19, 36, 13, 13, 18, 34,\n",
      "         6, 43, 26, 19, 21,  7, 18, 38, 26, 28])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters to be passed to the DataLoader\n",
    "data = list(zip(train_text, y_train))\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instantiate the DataLoader\n",
    "train_loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "data = list(zip(val_text, y_val))\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "# Instantiate the DataLoader\n",
    "val_loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "# Go through one loop\n",
    "counter = 0\n",
    "for batched_x, batched_y, batched_lengths in train_loader:\n",
    "  print(f\"Iteration {counter}\")\n",
    "  print(\"Batched Input:\")\n",
    "  print(batched_x)\n",
    "  print(\"Batched Labels:\")\n",
    "  print(batched_y)\n",
    "  print(\"Batched Lengths:\")\n",
    "  print(batched_lengths)\n",
    "  print(\"\")\n",
    "  counter += 1\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf31a480-af6b-4537-8389-dfd9df75c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_for_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "    return [pad_token]*window_size + sentence + [pad_token]*window_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3576a6e-91ae-474a-a4fb-26aff4c055f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens_to_inds(sentence, word_2_id):\n",
    "    return [word_2_id.get(t, word_2_id[\"<unk>\"]) for t in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e120bd5-d6a4-4fc3-a2cd-12480cc50a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(data, window_size, word_2_id):\n",
    "    \"\"\"\n",
    "    For some chunk of sentences and labels\n",
    "        -add winow padding\n",
    "        -pad for lengths using pad_sequence\n",
    "        -convert our labels to one-hots\n",
    "        -return padded inputs, one-hot labels, and lengths\n",
    "    \"\"\"\n",
    "    \n",
    "    x_s, y_s = zip(*data)\n",
    "\n",
    "    # deal with input sentences as we've seen\n",
    "    window_padded = [convert_tokens_to_inds(pad_sentence_for_window(sentence, window_size), word_2_id)\n",
    "                                                                                  for sentence in x_s]\n",
    "    # append zeros to each list of token ids in batch so that they are all the same length\n",
    "    padded = nn.utils.rnn.pad_sequence([torch.LongTensor(t) for t in window_padded], batch_first=True)\n",
    "    \n",
    "    # convert labels to one-hots\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for y in y_s:\n",
    "        lengths.append(len(y))\n",
    "        label = torch.zeros((len(y),2 ))\n",
    "        true = torch.LongTensor(y) \n",
    "        false = ~true.byte()\n",
    "        label[:, 0] = false\n",
    "        label[:, 1] = true\n",
    "        labels.append(label)\n",
    "    padded_labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "    \n",
    "    return padded.long(), padded_labels, torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31f331-88f2-44f6-bc19-158741f7b4f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf423d8f-9e29-4735-8f09-26dc9fe43f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWordWindowClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A one-layer, binary word-window classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, vocab_size, pad_idx=0):\n",
    "        super(SoftmaxWordWindowClassifier, self).__init__()\n",
    "        \"\"\"\n",
    "        Instance variables.\n",
    "        \"\"\"\n",
    "        self.window_size = 2*config[\"half_window\"]+1\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.hidden_dim = config[\"hidden_dim\"]\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "        self.freeze_embeddings = config[\"freeze_embeddings\"]\n",
    "        \n",
    "        \"\"\"\n",
    "        Embedding layer\n",
    "        -model holds an embedding for each layer in our vocab\n",
    "        -sets aside a special index in the embedding matrix for padding vector (of zeros)\n",
    "        -by default, embeddings are parameters (so gradients pass through them)\n",
    "        \"\"\"\n",
    "        self.embed_layer = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_idx)\n",
    "        if self.freeze_embeddings:\n",
    "            self.embed_layer.weight.requires_grad = False\n",
    "        \n",
    "        \"\"\"\n",
    "        Hidden layer\n",
    "        -we want to map embedded word windows of dim (window_size+1)*self.embed_dim to a hidden layer.\n",
    "        -nn.Sequential allows you to efficiently specify sequentially structured models\n",
    "            -first the linear transformation is evoked on the embedded word windows\n",
    "            -next the nonlinear transformation tanh is evoked.\n",
    "        \"\"\"\n",
    "        self.hidden_layer = nn.Sequential(nn.Linear(self.window_size*self.embed_dim, \n",
    "                                                    self.hidden_dim), \n",
    "                                          nn.GELU())\n",
    "        \n",
    "        \"\"\"\n",
    "        Output layer\n",
    "        -we want to map elements of the output layer (of size self.hidden dim) to a number of classes.\n",
    "        \"\"\"\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, self.num_classes)\n",
    "        \n",
    "        \"\"\"\n",
    "        Softmax\n",
    "        -The final step of the softmax classifier: mapping final hidden layer to class scores.\n",
    "        -pytorch has both logsoftmax and softmax functions (and many others)\n",
    "        -since our loss is the negative LOG likelihood, we use logsoftmax\n",
    "        -technically you can take the softmax, and take the log but PyTorch's implementation\n",
    "         is optimized to avoid numerical underflow issues.\n",
    "        \"\"\"\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Let B:= batch_size\n",
    "            L:= window-padded sentence length\n",
    "            D:= self.embed_dim\n",
    "            S:= self.window_size\n",
    "            H:= self.hidden_dim\n",
    "            \n",
    "        inputs: a (B, L) tensor of token indices\n",
    "        \"\"\"\n",
    "        B, L = inputs.size()\n",
    "        \n",
    "        \"\"\"\n",
    "        Reshaping.\n",
    "        Takes in a (B, L) LongTensor\n",
    "        Outputs a (B, L~, S) LongTensor\n",
    "        \"\"\"\n",
    "        # Fist, get our word windows for each word in our input.\n",
    "        token_windows = inputs.unfold(1, self.window_size, 1)\n",
    "        _, adjusted_length, _ = token_windows.size()\n",
    "        \n",
    "        # Good idea to do internal tensor-size sanity checks, at the least in comments!\n",
    "        assert token_windows.size() == (B, adjusted_length, self.window_size)\n",
    "        \n",
    "        \"\"\"\n",
    "        Embedding.\n",
    "        Takes in a torch.LongTensor of size (B, L~, S) \n",
    "        Outputs a (B, L~, S, D) FloatTensor.\n",
    "        \"\"\"\n",
    "        embedded_windows = self.embed_layer(token_windows)\n",
    "        \n",
    "        \"\"\"\n",
    "        Reshaping.\n",
    "        Takes in a (B, L~, S, D) FloatTensor.\n",
    "        Resizes it into a (B, L~, S*D) FloatTensor.\n",
    "        -1 argument \"infers\" what the last dimension should be based on leftover axes.\n",
    "        \"\"\"\n",
    "        embedded_windows = embedded_windows.view(B, adjusted_length, -1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Layer 1.\n",
    "        Takes in a (B, L~, S*D) FloatTensor.\n",
    "        Resizes it into a (B, L~, H) FloatTensor\n",
    "        \"\"\"\n",
    "        layer_1 = self.hidden_layer(embedded_windows)\n",
    "        \n",
    "        \"\"\"\n",
    "        Layer 2\n",
    "        Takes in a (B, L~, H) FloatTensor.\n",
    "        Resizes it into a (B, L~, 2) FloatTensor.\n",
    "        \"\"\"\n",
    "        output = self.output_layer(layer_1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Softmax.\n",
    "        Takes in a (B, L~, 2) FloatTensor of unnormalized class scores.\n",
    "        Outputs a (B, L~, 2) FloatTensor of (log-)normalized class scores.\n",
    "        \"\"\"\n",
    "        output = self.log_softmax(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e41475-71b6-4f35-9e45-90f889c6371c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c83babf-3585-44bf-9f1d-fa99e0d3d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(outputs, labels, lengths):\n",
    "    \"\"\"Computes negative LL loss on a batch of model predictions.\"\"\"\n",
    "    B, L, num_classes = outputs.size()\n",
    "    num_elems = lengths.sum().float()\n",
    "        \n",
    "    # get only the values with non-zero labels\n",
    "    loss = outputs*labels\n",
    "    \n",
    "    # rescale average\n",
    "    return -loss.sum() / num_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86984aa9-8b8d-4115-b0b9-9d8a62b5024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loss_function, optimizer, model, train_data):\n",
    "    \n",
    "    ## For each batch, we must reset the gradients\n",
    "    ## stored by the model.   \n",
    "    total_loss = 0\n",
    "    for batch, labels, lengths in train_data:\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # evoke model in training mode on batch\n",
    "        outputs = model.forward(batch)\n",
    "        # compute loss w.r.t batch\n",
    "        loss = loss_function(outputs, labels, lengths)\n",
    "        # pass gradients back, startiing on loss value\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # return the total to keep track of how you did this time around\n",
    "    return total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "145f0d2a-e7f6-4ba7-b0e9-b014130a6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(loss_function, model, val_data):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, labels, lengths in val_data:\n",
    "            outputs = model.forward(batch)\n",
    "            loss = loss_function(outputs, labels, lengths)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e72d4bee-5f32-4240-a460-d33a8864233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"batch_size\": 64,\n",
    "          \"half_window\": 2,\n",
    "          \"embed_dim\": 25,\n",
    "          \"hidden_dim\": 25,\n",
    "          \"num_classes\": 17,\n",
    "          \"freeze_embeddings\": False,\n",
    "         }\n",
    "learning_rate = .0002\n",
    "num_epochs = 1000\n",
    "model = SoftmaxWordWindowClassifier(config, len(word_to_ix))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3ea3f8d9-6674-4408-9941-7338cafdf2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fdda220f-b998-4b9c-a06e-2df0934acf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2631.4190690517426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    epoch_loss = train_epoch(loss_function, optimizer, model, train_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        losses.append(epoch_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80288234-32ca-4ab2-b551-ec2d60d4c1a6",
   "metadata": {},
   "source": [
    "# Training with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e2140-1d21-458d-9f21-95be7450f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 1/1000 [00:09<2:46:11,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 2399.1862387657166, Validation Loss: 242.26427030563354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 2/1000 [00:19<2:44:25,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1827.640622138977, Validation Loss: 214.08459424972534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 3/1000 [00:29<2:44:27,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1662.8007147312164, Validation Loss: 199.612934589386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 4/1000 [00:39<2:43:26,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1560.4916634559631, Validation Loss: 189.02400398254395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 5/1000 [00:49<2:42:52,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1478.5812537670135, Validation Loss: 179.28088545799255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                       | 6/1000 [00:59<2:43:40,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1403.178775548935, Validation Loss: 170.15749311447144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 7/1000 [01:09<2:43:01,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 1331.1526279449463, Validation Loss: 161.37489199638367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 8/1000 [01:18<2:41:02,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 1260.8680696487427, Validation Loss: 152.97770488262177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 9/1000 [01:28<2:39:54,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1194.8828990459442, Validation Loss: 144.69702684879303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 10/1000 [01:37<2:38:55,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1130.379192829132, Validation Loss: 136.86302483081818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 11/1000 [01:47<2:39:59,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 1069.5790224075317, Validation Loss: 129.56063604354858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 12/1000 [01:57<2:40:44,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 1013.068103313446, Validation Loss: 122.75724804401398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 13/1000 [02:07<2:40:32,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 960.0931547880173, Validation Loss: 116.4878740310669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 14/1000 [02:16<2:40:26,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 912.2265808582306, Validation Loss: 110.83514976501465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 15/1000 [02:26<2:40:24,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 869.3578637838364, Validation Loss: 105.83245933055878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 16/1000 [02:36<2:40:32,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 830.5753585100174, Validation Loss: 101.34004807472229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 17/1000 [02:46<2:40:36,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 797.0292812585831, Validation Loss: 97.35558438301086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 18/1000 [02:56<2:40:51,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 767.3879606723785, Validation Loss: 93.94716441631317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 19/1000 [03:06<2:40:40,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 740.9462887048721, Validation Loss: 90.97843205928802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 20/1000 [03:15<2:40:40,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 718.188074350357, Validation Loss: 88.24906575679779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 21/1000 [03:25<2:39:53,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 697.8855309486389, Validation Loss: 85.839635014534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 22/1000 [03:35<2:39:03,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss: 680.2904203534126, Validation Loss: 83.82533800601959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 23/1000 [03:45<2:39:43,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss: 664.6349579691887, Validation Loss: 82.01841139793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 24/1000 [03:54<2:38:57,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss: 650.7413860559464, Validation Loss: 80.35790830850601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 25/1000 [04:04<2:38:53,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss: 638.3943765163422, Validation Loss: 78.94441217184067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 26/1000 [04:14<2:39:22,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss: 627.5066362023354, Validation Loss: 77.59922933578491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 27/1000 [04:24<2:39:10,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss: 617.7297169566154, Validation Loss: 76.41875237226486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 28/1000 [04:34<2:38:42,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss: 608.8607105016708, Validation Loss: 75.36936861276627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 29/1000 [04:44<2:39:35,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss: 600.9561060667038, Validation Loss: 74.41926538944244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 30/1000 [04:54<2:42:23, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss: 593.5147258639336, Validation Loss: 73.61533051729202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 31/1000 [05:04<2:41:22,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss: 587.1118562221527, Validation Loss: 72.78000777959824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 32/1000 [05:14<2:41:38, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss: 580.8398065567017, Validation Loss: 72.05477887392044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 33/1000 [05:24<2:40:54,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss: 575.1541429162025, Validation Loss: 71.40856117010117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 34/1000 [05:35<2:45:25, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss: 570.0704293847084, Validation Loss: 70.75199729204178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▎                                     | 35/1000 [05:46<2:49:06, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss: 565.454756975174, Validation Loss: 70.20916122198105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 36/1000 [05:57<2:49:28, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss: 560.8672429323196, Validation Loss: 69.64635044336319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 37/1000 [06:07<2:47:17, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss: 556.8400486707687, Validation Loss: 69.17162996530533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 38/1000 [06:17<2:44:31, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss: 553.0435050725937, Validation Loss: 68.70770591497421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 39/1000 [06:27<2:45:31, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss: 549.3925052881241, Validation Loss: 68.2290952205658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 40/1000 [06:38<2:46:16, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss: 545.8481639027596, Validation Loss: 67.87332427501678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 41/1000 [06:47<2:41:57, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss: 542.5348016619682, Validation Loss: 67.3930401802063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 42/1000 [06:57<2:39:00,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss: 539.617248237133, Validation Loss: 67.05875414609909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 43/1000 [07:06<2:36:58,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss: 536.7124584913254, Validation Loss: 66.70396173000336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 44/1000 [07:16<2:36:24,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss: 534.0180584192276, Validation Loss: 66.34389835596085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▊                                     | 45/1000 [07:26<2:36:19,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss: 531.3006085753441, Validation Loss: 66.04273498058319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 46/1000 [07:36<2:35:12,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss: 528.937186896801, Validation Loss: 65.70463812351227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 47/1000 [07:45<2:34:43,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss: 526.749562561512, Validation Loss: 65.43421024084091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 48/1000 [07:55<2:33:51,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss: 524.5221205353737, Validation Loss: 65.1344575881958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 49/1000 [08:04<2:33:06,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss: 522.1657264828682, Validation Loss: 64.85905355215073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 50/1000 [08:14<2:32:42,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss: 520.2357334494591, Validation Loss: 64.66225153207779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 51/1000 [08:24<2:32:15,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 518.0534234642982, Validation Loss: 64.39890694618225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                     | 52/1000 [08:34<2:33:23,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss: 516.284256696701, Validation Loss: 64.15376907587051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                     | 53/1000 [08:43<2:33:45,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss: 514.3342781662941, Validation Loss: 63.94445204734802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                     | 54/1000 [08:53<2:33:01,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss: 512.6196287274361, Validation Loss: 63.71693176031113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▏                                    | 55/1000 [09:03<2:33:41,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss: 511.0995060801506, Validation Loss: 63.47188150882721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▏                                    | 56/1000 [09:13<2:34:29,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss: 509.5248489379883, Validation Loss: 63.332880795001984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▏                                    | 57/1000 [09:23<2:34:29,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss: 507.8508225083351, Validation Loss: 63.105906784534454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                    | 58/1000 [09:33<2:34:25,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss: 506.29287827014923, Validation Loss: 62.85134315490723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                    | 59/1000 [09:42<2:34:04,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss: 505.0451023578644, Validation Loss: 62.70168823003769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                    | 60/1000 [09:52<2:33:45,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss: 503.3996425271034, Validation Loss: 62.53201371431351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                    | 61/1000 [10:02<2:34:32,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss: 501.89446157217026, Validation Loss: 62.37287849187851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                    | 62/1000 [10:12<2:33:45,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train Loss: 500.8339214324951, Validation Loss: 62.20214658975601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                    | 63/1000 [10:22<2:33:23,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train Loss: 499.4913820028305, Validation Loss: 62.05520725250244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                    | 64/1000 [10:31<2:33:06,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train Loss: 498.39717549085617, Validation Loss: 61.84849315881729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                    | 65/1000 [10:41<2:32:05,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train Loss: 497.0477236509323, Validation Loss: 61.71797353029251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▌                                    | 66/1000 [10:51<2:31:24,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train Loss: 495.79089760780334, Validation Loss: 61.5893777012825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▌                                    | 67/1000 [11:00<2:30:41,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train Loss: 494.6786295771599, Validation Loss: 61.4318642616272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                    | 68/1000 [11:10<2:30:41,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train Loss: 493.67639350891113, Validation Loss: 61.307257294654846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                    | 69/1000 [11:20<2:32:08,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Train Loss: 492.5344173312187, Validation Loss: 61.199261367321014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                    | 70/1000 [11:30<2:32:50,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Train Loss: 491.6293307542801, Validation Loss: 61.06705588102341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                    | 71/1000 [11:40<2:33:29,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train Loss: 490.5094742178917, Validation Loss: 60.95920217037201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                    | 72/1000 [11:51<2:35:50, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train Loss: 489.57959109544754, Validation Loss: 60.81268173456192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                    | 73/1000 [12:00<2:34:28, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Train Loss: 488.6487748026848, Validation Loss: 60.65189188718796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                    | 74/1000 [12:10<2:32:30,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Train Loss: 487.31068736314774, Validation Loss: 60.56277400255203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▉                                    | 75/1000 [12:20<2:31:23,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Train Loss: 486.75079667568207, Validation Loss: 60.40961533784866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▉                                    | 76/1000 [12:29<2:30:45,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train Loss: 485.6860639452934, Validation Loss: 60.35526895523071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███                                    | 77/1000 [12:39<2:30:12,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Train Loss: 484.9160796403885, Validation Loss: 60.26249098777771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███                                    | 78/1000 [12:50<2:34:43, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train Loss: 483.9872117638588, Validation Loss: 60.15220504999161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███                                    | 79/1000 [13:00<2:36:14, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Train Loss: 483.2100595831871, Validation Loss: 60.023482263088226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███                                    | 80/1000 [13:10<2:35:29, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Train Loss: 482.3720082640648, Validation Loss: 59.92060971260071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                   | 81/1000 [13:20<2:33:49, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train Loss: 481.8064677119255, Validation Loss: 59.826124489307404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                   | 82/1000 [13:30<2:34:26, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train Loss: 481.05801653862, Validation Loss: 59.72056871652603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                   | 83/1000 [13:41<2:34:30, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Train Loss: 480.20820248126984, Validation Loss: 59.636007368564606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                   | 84/1000 [13:51<2:33:59, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Train Loss: 479.3851926922798, Validation Loss: 59.52732080221176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                   | 85/1000 [14:01<2:36:37, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Train Loss: 478.5249053835869, Validation Loss: 59.46916502714157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▎                                   | 86/1000 [14:12<2:36:29, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Train Loss: 477.75421661138535, Validation Loss: 59.357919692993164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▍                                   | 87/1000 [14:22<2:35:18, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Train Loss: 477.1475319862366, Validation Loss: 59.25179976224899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▍                                   | 88/1000 [14:32<2:35:14, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train Loss: 476.56393951177597, Validation Loss: 59.21249109506607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▍                                   | 89/1000 [14:42<2:35:41, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Train Loss: 475.8047494292259, Validation Loss: 59.062091410160065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▌                                   | 90/1000 [14:52<2:34:29, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss: 475.280170917511, Validation Loss: 59.03305071592331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▌                                   | 91/1000 [15:02<2:31:51, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss: 474.66054970026016, Validation Loss: 58.982138991355896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▌                                   | 92/1000 [15:11<2:29:34,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss: 474.0272791981697, Validation Loss: 58.84682631492615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                   | 93/1000 [15:21<2:27:58,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss: 473.25209897756577, Validation Loss: 58.79998004436493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                   | 94/1000 [15:31<2:26:58,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss: 472.60276609659195, Validation Loss: 58.72554588317871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▋                                   | 95/1000 [15:40<2:27:18,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss: 472.10742723941803, Validation Loss: 58.62646967172623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▋                                   | 96/1000 [15:51<2:29:24,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Train Loss: 471.4437925815582, Validation Loss: 58.55169212818146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                   | 97/1000 [16:01<2:30:26, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Train Loss: 470.82508927583694, Validation Loss: 58.492278695106506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                   | 98/1000 [16:11<2:32:25, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss: 470.2990577220917, Validation Loss: 58.40868782997131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                   | 99/1000 [16:21<2:30:02,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Train Loss: 469.7922787666321, Validation Loss: 58.35045325756073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 100/1000 [16:31<2:28:05,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Train Loss: 469.1661691069603, Validation Loss: 58.256392419338226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                  | 101/1000 [16:40<2:27:18,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss: 468.7812477350235, Validation Loss: 58.18306940793991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                  | 102/1000 [16:50<2:27:10,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Train Loss: 468.10883408784866, Validation Loss: 58.12512129545212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                  | 103/1000 [17:00<2:26:48,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: Train Loss: 467.62773072719574, Validation Loss: 58.07031470537186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                  | 104/1000 [17:10<2:26:35,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: Train Loss: 467.19757026433945, Validation Loss: 58.037138879299164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                  | 105/1000 [17:20<2:27:18,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: Train Loss: 466.5986179113388, Validation Loss: 57.9423491358757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████                                  | 106/1000 [17:30<2:26:32,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: Train Loss: 466.22122102975845, Validation Loss: 57.86351281404495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████                                  | 107/1000 [17:39<2:26:39,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: Train Loss: 465.6344636082649, Validation Loss: 57.86218202114105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████                                  | 108/1000 [17:49<2:26:40,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: Train Loss: 465.06206798553467, Validation Loss: 57.73392504453659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▏                                 | 109/1000 [17:59<2:26:14,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: Train Loss: 464.49375808238983, Validation Loss: 57.694220423698425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▏                                 | 110/1000 [18:09<2:25:52,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: Train Loss: 464.189756333828, Validation Loss: 57.61332404613495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▏                                 | 111/1000 [18:19<2:25:46,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Train Loss: 463.68559366464615, Validation Loss: 57.54221838712692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▎                                 | 112/1000 [18:29<2:25:25,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: Train Loss: 463.1826862692833, Validation Loss: 57.510450661182404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▎                                 | 113/1000 [18:38<2:24:25,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: Train Loss: 462.8717569708824, Validation Loss: 57.41861408948898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▎                                 | 114/1000 [18:48<2:25:06,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: Train Loss: 462.48618519306183, Validation Loss: 57.41861778497696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▎                                 | 115/1000 [18:59<2:27:31, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: Train Loss: 461.87269669771194, Validation Loss: 57.41020691394806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▍                                 | 116/1000 [19:09<2:27:01,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: Train Loss: 461.52985072135925, Validation Loss: 57.33085346221924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▍                                 | 117/1000 [19:18<2:25:28,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: Train Loss: 461.2245590686798, Validation Loss: 57.292318761348724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▍                                 | 118/1000 [19:28<2:25:14,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: Train Loss: 460.5650782585144, Validation Loss: 57.18761324882507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▌                                 | 119/1000 [19:38<2:25:08,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: Train Loss: 460.2751324772835, Validation Loss: 57.161215007305145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▌                                 | 120/1000 [19:48<2:27:10, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: Train Loss: 459.75204664468765, Validation Loss: 57.09476673603058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▌                                 | 121/1000 [19:58<2:25:46,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Train Loss: 459.302437543869, Validation Loss: 57.058349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▋                                 | 122/1000 [20:08<2:24:48,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: Train Loss: 458.96811455488205, Validation Loss: 56.96448999643326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▋                                 | 123/1000 [20:18<2:23:40,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Train Loss: 458.60093200206757, Validation Loss: 56.95792478322983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▋                                 | 124/1000 [20:28<2:24:07,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: Train Loss: 458.29983854293823, Validation Loss: 56.90649873018265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▊                                 | 125/1000 [20:37<2:23:39,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: Train Loss: 457.6146978735924, Validation Loss: 56.82741177082062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▊                                 | 126/1000 [20:47<2:23:48,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: Train Loss: 457.38472163677216, Validation Loss: 56.782547771930695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▊                                 | 127/1000 [20:57<2:24:48,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: Train Loss: 456.95446330308914, Validation Loss: 56.77556270360947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▊                                 | 128/1000 [21:07<2:23:58,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: Train Loss: 456.78636968135834, Validation Loss: 56.705500423908234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▉                                 | 129/1000 [21:17<2:23:12,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: Train Loss: 456.3202030658722, Validation Loss: 56.66060221195221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▉                                 | 130/1000 [21:27<2:22:40,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: Train Loss: 455.91806852817535, Validation Loss: 56.5936821103096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▉                                 | 131/1000 [21:37<2:23:18,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Train Loss: 455.5864469408989, Validation Loss: 56.579178512096405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████                                 | 132/1000 [21:47<2:25:24, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: Train Loss: 455.1037484407425, Validation Loss: 56.55087608098984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████                                 | 133/1000 [21:58<2:26:40, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: Train Loss: 454.7736804485321, Validation Loss: 56.462176859378815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████                                 | 134/1000 [22:08<2:27:32, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Train Loss: 454.58867305517197, Validation Loss: 56.45351356267929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▏                                | 135/1000 [22:18<2:28:01, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: Train Loss: 454.0592074394226, Validation Loss: 56.39820945262909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▏                                | 136/1000 [22:29<2:28:25, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: Train Loss: 453.69113379716873, Validation Loss: 56.36620372533798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▏                                | 137/1000 [22:39<2:26:14, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136: Train Loss: 453.4318962097168, Validation Loss: 56.31699466705322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▏                                | 138/1000 [22:48<2:24:23, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137: Train Loss: 453.07875245809555, Validation Loss: 56.24252778291702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▎                                | 139/1000 [22:58<2:23:27, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: Train Loss: 452.7995412349701, Validation Loss: 56.24489587545395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▎                                | 140/1000 [23:08<2:22:29,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139: Train Loss: 452.37471306324005, Validation Loss: 56.167394042015076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▎                                | 141/1000 [23:18<2:21:35,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: Train Loss: 452.1068888902664, Validation Loss: 56.144634783267975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                | 142/1000 [23:28<2:20:52,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141: Train Loss: 451.7832096219063, Validation Loss: 56.089859187603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                | 143/1000 [23:37<2:20:15,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142: Train Loss: 451.4393817782402, Validation Loss: 56.062330305576324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                | 144/1000 [23:48<2:21:50,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143: Train Loss: 451.16116243600845, Validation Loss: 56.061093747615814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▌                                | 145/1000 [23:58<2:23:17, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144: Train Loss: 450.67146641016006, Validation Loss: 55.95199394226074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▌                                | 146/1000 [24:08<2:23:06, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145: Train Loss: 450.3575921654701, Validation Loss: 55.93361645936966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▌                                | 147/1000 [24:18<2:21:46,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146: Train Loss: 450.28244626522064, Validation Loss: 55.88812470436096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▌                                | 148/1000 [24:27<2:20:50,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147: Train Loss: 449.8616232275963, Validation Loss: 55.845411598682404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 149/1000 [24:37<2:19:59,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148: Train Loss: 449.427132666111, Validation Loss: 55.8274502158165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 150/1000 [24:47<2:19:05,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: Train Loss: 449.1257266998291, Validation Loss: 55.80483812093735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 151/1000 [24:57<2:18:31,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: Train Loss: 448.87145733833313, Validation Loss: 55.773354172706604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▊                                | 152/1000 [25:07<2:18:44,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: Train Loss: 448.5311220884323, Validation Loss: 55.71892762184143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▊                                | 153/1000 [25:16<2:18:02,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152: Train Loss: 448.36845034360886, Validation Loss: 55.68871885538101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▊                                | 154/1000 [25:26<2:17:53,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: Train Loss: 448.00250911712646, Validation Loss: 55.652022659778595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████▉                                | 155/1000 [25:36<2:17:55,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154: Train Loss: 447.6461044549942, Validation Loss: 55.64695918560028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████▉                                | 156/1000 [25:46<2:20:09,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155: Train Loss: 447.27666479349136, Validation Loss: 55.60145437717438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████▉                                | 157/1000 [25:56<2:19:16,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: Train Loss: 447.0831338763237, Validation Loss: 55.51375663280487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████                                | 158/1000 [26:06<2:18:16,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157: Train Loss: 446.87872380018234, Validation Loss: 55.49279820919037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████                                | 159/1000 [26:15<2:17:34,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158: Train Loss: 446.714361846447, Validation Loss: 55.44681751728058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████                                | 160/1000 [26:25<2:18:06,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159: Train Loss: 446.22931057214737, Validation Loss: 55.42635041475296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████                                | 161/1000 [26:35<2:17:10,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160: Train Loss: 445.89799922704697, Validation Loss: 55.39454221725464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▏                               | 162/1000 [26:45<2:16:54,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161: Train Loss: 445.63508254289627, Validation Loss: 55.40883618593216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▏                               | 163/1000 [26:55<2:17:02,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162: Train Loss: 445.3245413303375, Validation Loss: 55.31633943319321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▏                               | 164/1000 [27:05<2:18:16,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163: Train Loss: 445.19175934791565, Validation Loss: 55.28299522399902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▎                               | 165/1000 [27:15<2:17:50,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164: Train Loss: 444.86004489660263, Validation Loss: 55.241144239902496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▎                               | 166/1000 [27:25<2:17:24,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165: Train Loss: 444.6577200293541, Validation Loss: 55.235180377960205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▎                               | 167/1000 [27:34<2:17:04,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166: Train Loss: 444.22756522893906, Validation Loss: 55.183632612228394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▍                               | 168/1000 [27:44<2:16:00,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167: Train Loss: 443.93393486738205, Validation Loss: 55.1406791806221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▍                               | 169/1000 [27:54<2:15:17,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168: Train Loss: 443.674396276474, Validation Loss: 55.10059779882431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▍                               | 170/1000 [28:04<2:14:59,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169: Train Loss: 443.48783898353577, Validation Loss: 55.08417105674744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▍                               | 171/1000 [28:13<2:15:10,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: Train Loss: 443.38176441192627, Validation Loss: 55.14325225353241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▌                               | 172/1000 [28:23<2:15:17,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171: Train Loss: 442.8809868693352, Validation Loss: 55.044660329818726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▌                               | 173/1000 [28:34<2:18:22, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172: Train Loss: 442.61627382040024, Validation Loss: 55.00123405456543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▌                               | 174/1000 [28:45<2:21:02, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173: Train Loss: 442.44710594415665, Validation Loss: 55.007188975811005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▋                               | 175/1000 [28:55<2:19:50, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174: Train Loss: 442.3722492456436, Validation Loss: 54.907162845134735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▋                               | 176/1000 [29:04<2:18:01, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175: Train Loss: 442.1196925640106, Validation Loss: 54.90066468715668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▋                               | 177/1000 [29:14<2:16:50,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: Train Loss: 441.76182782649994, Validation Loss: 54.86978530883789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▊                               | 178/1000 [29:24<2:15:48,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: Train Loss: 441.50224298238754, Validation Loss: 54.815221309661865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▊                               | 179/1000 [29:34<2:14:52,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178: Train Loss: 441.26462399959564, Validation Loss: 54.80634558200836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▊                               | 180/1000 [29:43<2:14:55,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: Train Loss: 440.99430733919144, Validation Loss: 54.77156800031662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▉                               | 181/1000 [29:54<2:16:39, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: Train Loss: 440.8963026404381, Validation Loss: 54.76250743865967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▉                               | 182/1000 [30:04<2:15:35,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181: Train Loss: 440.416259765625, Validation Loss: 54.73505401611328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▉                               | 183/1000 [30:13<2:14:23,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182: Train Loss: 440.289061665535, Validation Loss: 54.68681299686432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████▉                               | 184/1000 [30:23<2:13:28,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183: Train Loss: 440.09108650684357, Validation Loss: 54.648460388183594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████                               | 185/1000 [30:33<2:13:03,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184: Train Loss: 439.6590966582298, Validation Loss: 54.65161681175232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████                               | 186/1000 [30:43<2:12:50,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185: Train Loss: 439.66547751426697, Validation Loss: 54.63733226060867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████                               | 187/1000 [30:52<2:12:38,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186: Train Loss: 439.41027092933655, Validation Loss: 54.59681326150894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▏                              | 188/1000 [31:02<2:12:50,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187: Train Loss: 439.1745924949646, Validation Loss: 54.55300223827362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▏                              | 189/1000 [31:12<2:12:39,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188: Train Loss: 438.74075335264206, Validation Loss: 54.55173712968826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▏                              | 190/1000 [31:22<2:11:55,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189: Train Loss: 438.4071799516678, Validation Loss: 54.49227750301361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▎                              | 191/1000 [31:32<2:13:00,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190: Train Loss: 438.25756043195724, Validation Loss: 54.47671151161194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▎                              | 192/1000 [31:42<2:12:53,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191: Train Loss: 438.10041731595993, Validation Loss: 54.4257527589798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▎                              | 193/1000 [31:52<2:13:06,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192: Train Loss: 437.83332592248917, Validation Loss: 54.391445994377136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▎                              | 194/1000 [32:01<2:12:23,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193: Train Loss: 437.57326847314835, Validation Loss: 54.41724622249603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▍                              | 195/1000 [32:11<2:12:17,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194: Train Loss: 437.5459473133087, Validation Loss: 54.37029725313187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▍                              | 196/1000 [32:21<2:12:15,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195: Train Loss: 437.1750079393387, Validation Loss: 54.32318866252899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▍                              | 197/1000 [32:31<2:11:12,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196: Train Loss: 436.8873091340065, Validation Loss: 54.27647268772125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 198/1000 [32:40<2:10:11,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: Train Loss: 436.72871339321136, Validation Loss: 54.273267567157745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 199/1000 [32:50<2:10:57,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198: Train Loss: 436.51401340961456, Validation Loss: 54.2600274682045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 200/1000 [33:00<2:09:44,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: Train Loss: 436.37344229221344, Validation Loss: 54.24972140789032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▋                              | 201/1000 [33:09<2:08:45,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Train Loss: 435.99750727415085, Validation Loss: 54.19061362743378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▋                              | 202/1000 [33:19<2:07:59,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201: Train Loss: 435.99550384283066, Validation Loss: 54.13112986087799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▋                              | 203/1000 [33:28<2:07:30,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202: Train Loss: 435.59989005327225, Validation Loss: 54.11039799451828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▊                              | 204/1000 [33:39<2:09:32,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203: Train Loss: 435.3595931529999, Validation Loss: 54.10770744085312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▊                              | 205/1000 [33:48<2:09:40,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204: Train Loss: 435.16692036390305, Validation Loss: 54.08404904603958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▊                              | 206/1000 [33:58<2:09:05,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205: Train Loss: 434.9332684278488, Validation Loss: 54.03575974702835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▊                              | 207/1000 [34:08<2:09:09,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206: Train Loss: 434.7509461045265, Validation Loss: 54.03415638208389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▉                              | 208/1000 [34:18<2:09:00,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: Train Loss: 434.68781608343124, Validation Loss: 54.01238536834717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▉                              | 209/1000 [34:28<2:09:11,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208: Train Loss: 434.34101915359497, Validation Loss: 53.97575330734253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▉                              | 210/1000 [34:37<2:08:12,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: Train Loss: 434.2597594857216, Validation Loss: 53.95667189359665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████                              | 211/1000 [34:47<2:08:18,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210: Train Loss: 433.9911772608757, Validation Loss: 53.8854022026062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████                              | 212/1000 [34:57<2:07:53,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211: Train Loss: 433.9382892847061, Validation Loss: 53.895218312740326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████                              | 213/1000 [35:07<2:08:56,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212: Train Loss: 433.3587518334389, Validation Loss: 53.88970184326172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▏                             | 214/1000 [35:17<2:09:08,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213: Train Loss: 433.4766393303871, Validation Loss: 53.87968039512634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▏                             | 215/1000 [35:27<2:09:37,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214: Train Loss: 433.1923042535782, Validation Loss: 53.831677198410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▏                             | 216/1000 [35:36<2:09:08,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215: Train Loss: 432.8902302980423, Validation Loss: 53.8389927148819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▏                             | 217/1000 [35:46<2:08:44,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216: Train Loss: 432.72176492214203, Validation Loss: 53.736135363578796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▎                             | 218/1000 [35:56<2:08:21,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217: Train Loss: 432.5271792411804, Validation Loss: 53.6877059340477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▎                             | 219/1000 [36:06<2:08:24,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218: Train Loss: 432.2806792855263, Validation Loss: 53.71783924102783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▎                             | 220/1000 [36:16<2:10:26, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219: Train Loss: 431.9956026673317, Validation Loss: 53.70941573381424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▍                             | 221/1000 [36:27<2:12:03, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220: Train Loss: 431.88751941919327, Validation Loss: 53.674383878707886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▍                             | 222/1000 [36:37<2:11:50, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221: Train Loss: 431.61556524038315, Validation Loss: 53.62677335739136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▍                             | 223/1000 [36:47<2:09:39, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222: Train Loss: 431.5425323843956, Validation Loss: 53.63726830482483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▌                             | 224/1000 [36:57<2:10:31, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223: Train Loss: 431.29987984895706, Validation Loss: 53.60145324468613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▌                             | 225/1000 [37:08<2:14:01, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224: Train Loss: 430.9276941418648, Validation Loss: 53.560534715652466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████▌                             | 226/1000 [37:19<2:15:05, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225: Train Loss: 430.8782313466072, Validation Loss: 53.564945697784424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████▋                             | 227/1000 [37:29<2:14:59, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226: Train Loss: 430.6831773519516, Validation Loss: 53.53009009361267\n"
     ]
    }
   ],
   "source": [
    "# Training loop with early stopping\n",
    "losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    epoch_loss = train_epoch(loss_function, optimizer, model, train_loader)\n",
    "    val_loss = validate_epoch(loss_function, model, val_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        losses.append(epoch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {epoch}: Train Loss: {epoch_loss}, Validation Loss: {val_loss}')\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 8:  # patience\n",
    "                print(\"Early stopping due to validation loss not improving.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f06a1-0459-4e9e-be4b-51a23bb22409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78f73b2c-23f7-439f-b3c8-76f7dd72b243",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1c423fd5-a333-4470-9ef2-77f2a6948384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 14, 1, 1, 12, 0, 12, 1, 16, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 14, 1, 1, 12, 0, 12, 1, 16, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "for test_instance, labs, _ in val_loader:\n",
    "    outputs = model.forward(test_instance)\n",
    "    # print(outputs[0])\n",
    "    for o in outputs:\n",
    "        fdir=torch.argmax(o,dim=1).tolist()\n",
    "        for vy in fdir:\n",
    "            y_pred.append(vy)\n",
    "    for l in labs:\n",
    "        fdir=torch.argmax(outputs[0], dim=1).tolist()\n",
    "        for vx in fdir:\n",
    "            y_true.append(vx)\n",
    "    # print(test_instance)\n",
    "    # print(len(outputs),\" \",len(test_instance))\n",
    "    # print(torch.argmax(outputs[0], dim=1))\n",
    "    # print(labs[0])\n",
    "    # print(torch.argmax(labs, dim=2))\n",
    "print(y_true[0:5],\"\\n\",y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e184c6f-ee28-476c-b779-94e9e4829344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25be8ec-e6ad-497a-b054-0fbccab1ead4",
   "metadata": {},
   "source": [
    "# evaluating testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808cc09-4bd9-47ff-94af-b4ba920847ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('ner_val')\n",
    "testdt = list(dt['sentence']).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bd9d2-5608-4292-88e0-46f941c39f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be passed to the DataLoader\n",
    "\n",
    "data = list(zip(train_text, y_train))\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instantiate the DataLoader\n",
    "train_loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "data = list(zip(val_text, y_val))\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "# Instantiate the DataLoader\n",
    "val_loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "# Go through one loop\n",
    "counter = 0\n",
    "for batched_x, batched_y, batched_lengths in train_loader:\n",
    "  print(f\"Iteration {counter}\")\n",
    "  print(\"Batched Input:\")\n",
    "  print(batched_x)\n",
    "  print(\"Batched Labels:\")\n",
    "  print(batched_y)\n",
    "  print(\"Batched Lengths:\")\n",
    "  print(batched_lengths)\n",
    "  print(\"\")\n",
    "  counter += 1\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
