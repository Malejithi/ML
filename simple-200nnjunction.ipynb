{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7834045,"sourceType":"datasetVersion","datasetId":4591720}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing the pandas module for\n# data frame\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n\n\n\n# load the data set into train variable.\ntrain = pd.read_csv('/kaggle/input/trafficvehiclesjunction/traffic.csv')\ntrain = train.drop('ID', axis=1)\n\n# display top 5 values of data set\ntrain.head()\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fE-Fq8FabCba","outputId":"b109000c-2908-48c6-d627-97337118ed67","execution":{"iopub.status.busy":"2024-03-28T11:16:01.879087Z","iopub.execute_input":"2024-03-28T11:16:01.880207Z","iopub.status.idle":"2024-03-28T11:16:05.667235Z","shell.execute_reply.started":"2024-03-28T11:16:01.880149Z","shell.execute_reply":"2024-03-28T11:16:05.665540Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"              DateTime  Junction  Vehicles\n0  2015-11-01 00:00:00         1        15\n1  2015-11-01 01:00:00         1        13\n2  2015-11-01 02:00:00         1        10\n3  2015-11-01 03:00:00         1         7\n4  2015-11-01 04:00:00         1         9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTime</th>\n      <th>Junction</th>\n      <th>Vehicles</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-11-01 00:00:00</td>\n      <td>1</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-11-01 01:00:00</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-11-01 02:00:00</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-11-01 03:00:00</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-11-01 04:00:00</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# function to get all data from time stamp\n\n# get date\ndef get_dom(dt):\n\treturn dt.day\n\n# get week day\ndef get_weekday(dt):\n\treturn dt.weekday()\n\n# get hour\ndef get_hour(dt):\n\treturn dt.hour\n\n# get year\ndef get_year(dt):\n\treturn dt.year\n\n# get month\ndef get_month(dt):\n\treturn dt.month\n\n# get year day\ndef get_dayofyear(dt):\n\treturn dt.dayofyear\n\n# get year week\ndef get_weekofyear(dt):\n\treturn dt.weekofyear\n\n\ntrain['DateTime'] = train['DateTime'].map(pd.to_datetime)\ntrain['date'] = train['DateTime'].map(get_dom)\ntrain['weekday'] = train['DateTime'].map(get_weekday)\ntrain['hour'] = train['DateTime'].map(get_hour)\ntrain['month'] = train['DateTime'].map(get_month)\ntrain['year'] = train['DateTime'].map(get_year)\ntrain['dayofyear'] = train['DateTime'].map(get_dayofyear)\ntrain['weekofyear'] = train['DateTime'].map(get_weekofyear)\n\n# display\ntrain.head()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"23Rldh5LbUdE","outputId":"cd2258ae-0e25-4885-8534-b16ed740a153","execution":{"iopub.status.busy":"2024-03-28T11:16:05.669866Z","iopub.execute_input":"2024-03-28T11:16:05.670432Z","iopub.status.idle":"2024-03-28T11:16:39.652137Z","shell.execute_reply.started":"2024-03-28T11:16:05.670384Z","shell.execute_reply":"2024-03-28T11:16:39.650887Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"             DateTime  Junction  Vehicles  date  weekday  hour  month  year  \\\n0 2015-11-01 00:00:00         1        15     1        6     0     11  2015   \n1 2015-11-01 01:00:00         1        13     1        6     1     11  2015   \n2 2015-11-01 02:00:00         1        10     1        6     2     11  2015   \n3 2015-11-01 03:00:00         1         7     1        6     3     11  2015   \n4 2015-11-01 04:00:00         1         9     1        6     4     11  2015   \n\n   dayofyear  weekofyear  \n0        305          44  \n1        305          44  \n2        305          44  \n3        305          44  \n4        305          44  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTime</th>\n      <th>Junction</th>\n      <th>Vehicles</th>\n      <th>date</th>\n      <th>weekday</th>\n      <th>hour</th>\n      <th>month</th>\n      <th>year</th>\n      <th>dayofyear</th>\n      <th>weekofyear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-11-01 00:00:00</td>\n      <td>1</td>\n      <td>15</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-11-01 01:00:00</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-11-01 02:00:00</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-11-01 03:00:00</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-11-01 04:00:00</td>\n      <td>1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.to_csv('file1.csv')","metadata":{"id":"z2OS_Z1Rhm6I","execution":{"iopub.status.busy":"2024-03-28T11:16:39.654175Z","iopub.execute_input":"2024-03-28T11:16:39.654952Z","iopub.status.idle":"2024-03-28T11:16:40.067124Z","shell.execute_reply.started":"2024-03-28T11:16:39.654907Z","shell.execute_reply":"2024-03-28T11:16:40.065889Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# display top 5 values of data set\n# train = train[train['Junction'] == 1]\ntrain.head()","metadata":{"id":"FrSjpz3pgAUu","execution":{"iopub.status.busy":"2024-03-28T11:16:40.070505Z","iopub.execute_input":"2024-03-28T11:16:40.072255Z","iopub.status.idle":"2024-03-28T11:16:40.091650Z","shell.execute_reply.started":"2024-03-28T11:16:40.072179Z","shell.execute_reply":"2024-03-28T11:16:40.089699Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             DateTime  Junction  Vehicles  date  weekday  hour  month  year  \\\n0 2015-11-01 00:00:00         1        15     1        6     0     11  2015   \n1 2015-11-01 01:00:00         1        13     1        6     1     11  2015   \n2 2015-11-01 02:00:00         1        10     1        6     2     11  2015   \n3 2015-11-01 03:00:00         1         7     1        6     3     11  2015   \n4 2015-11-01 04:00:00         1         9     1        6     4     11  2015   \n\n   dayofyear  weekofyear  \n0        305          44  \n1        305          44  \n2        305          44  \n3        305          44  \n4        305          44  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTime</th>\n      <th>Junction</th>\n      <th>Vehicles</th>\n      <th>date</th>\n      <th>weekday</th>\n      <th>hour</th>\n      <th>month</th>\n      <th>year</th>\n      <th>dayofyear</th>\n      <th>weekofyear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-11-01 00:00:00</td>\n      <td>1</td>\n      <td>15</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-11-01 01:00:00</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-11-01 02:00:00</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-11-01 03:00:00</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-11-01 04:00:00</td>\n      <td>1</td>\n      <td>9</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# train = train.drop(['Junction'], axis=1)\nprint(train.columns)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T11:16:40.094001Z","iopub.execute_input":"2024-03-28T11:16:40.097010Z","iopub.status.idle":"2024-03-28T11:16:40.105012Z","shell.execute_reply.started":"2024-03-28T11:16:40.096938Z","shell.execute_reply":"2024-03-28T11:16:40.103651Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Index(['DateTime', 'Junction', 'Vehicles', 'date', 'weekday', 'hour', 'month',\n       'year', 'dayofyear', 'weekofyear'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"# there is no use of DateTime module\n# so remove it\ntrain = train.drop(['DateTime'], axis=1)\n\n# separating class label for training the data\ntrain1 = train.drop(['Vehicles'], axis=1)\n\n# class label is stored in target\ntarget = train['Vehicles']\n\nprint(train1.head())\ntarget.head()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"pIZO7QaRb8Gl","outputId":"dc47bb62-fd94-4070-a418-9acf379132d2","execution":{"iopub.status.busy":"2024-03-28T11:16:40.106732Z","iopub.execute_input":"2024-03-28T11:16:40.107653Z","iopub.status.idle":"2024-03-28T11:16:40.140529Z","shell.execute_reply.started":"2024-03-28T11:16:40.107603Z","shell.execute_reply":"2024-03-28T11:16:40.139052Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"   Junction  date  weekday  hour  month  year  dayofyear  weekofyear\n0         1     1        6     0     11  2015        305          44\n1         1     1        6     1     11  2015        305          44\n2         1     1        6     2     11  2015        305          44\n3         1     1        6     3     11  2015        305          44\n4         1     1        6     4     11  2015        305          44\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0    15\n1    13\n2    10\n3     7\n4     9\nName: Vehicles, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"target = pd.read_csv('/kaggle/working/file1.csv')\n\n# separating class label for training the data\ntrain1 = train.drop('Vehicles', axis=1)\n\n# class label is stored in target\ntarget = train['Vehicles']\n\ntrain1.head()\n#target.head()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"q0YoImveedzx","outputId":"d5926b25-f54c-4de8-fe2e-99ba9567c001","execution":{"iopub.status.busy":"2024-03-28T11:16:40.142392Z","iopub.execute_input":"2024-03-28T11:16:40.142947Z","iopub.status.idle":"2024-03-28T11:16:40.260190Z","shell.execute_reply.started":"2024-03-28T11:16:40.142898Z","shell.execute_reply":"2024-03-28T11:16:40.258543Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Junction  date  weekday  hour  month  year  dayofyear  weekofyear\n0         1     1        6     0     11  2015        305          44\n1         1     1        6     1     11  2015        305          44\n2         1     1        6     2     11  2015        305          44\n3         1     1        6     3     11  2015        305          44\n4         1     1        6     4     11  2015        305          44","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Junction</th>\n      <th>date</th>\n      <th>weekday</th>\n      <th>hour</th>\n      <th>month</th>\n      <th>year</th>\n      <th>dayofyear</th>\n      <th>weekofyear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>11</td>\n      <td>2015</td>\n      <td>305</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# train1 = pd.read_csv('/kaggle/working/train1.csv')\n# train1 = train1.fillna(train1.mean())\n# target = pd.read_csv('/kaggle/working/target.csv')\n#importing Random forest\nfrom sklearn.ensemble import RandomForestRegressor\n\n#defining the RandomForestRegressor\n#m1=RandomForestRegressor(\n# m1.fit(train1,target)\n#testing\n# m1.predict([[11,6,0,1,2015,11,2]])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"AC_9N-Pwb_ff","outputId":"b36e22d6-9171-4e84-9d43-b55e333967b8","execution":{"iopub.status.busy":"2024-03-28T11:22:14.781285Z","iopub.execute_input":"2024-03-28T11:22:14.781906Z","iopub.status.idle":"2024-03-28T11:22:14.789554Z","shell.execute_reply.started":"2024-03-28T11:22:14.781863Z","shell.execute_reply":"2024-03-28T11:22:14.787632Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nX_train, X_test, y_train, y_test = train_test_split(train1, target, test_size=0.2, random_state=42)\n\n# Create and train the model\n# model = DecisionTreeClassifier(random_state=42)\n# Compile the model\nm1 = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1)  # Output layer for regression\n])\nm1.compile(optimizer='adam', loss='mean_squared_error')\n# Define callbacks\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=15, monitor='val_loss'),  # Early stopping\n    tf.keras.callbacks.ModelCheckpoint(filepath='model_checkpoint.keras', save_best_only=True),  # Model checkpoint\n    tf.keras.callbacks.TensorBoard(log_dir='./logs')  # TensorBoard for visualization\n]\n# Train the model\nhisotry = m1.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2,callbacks=callbacks)\nm1 = tf.keras.models.load_model('model_checkpoint.keras')\ny_pred = m1.predict(X_test)\n# Evaluate the model\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Squared Error: {mse}')\nprint(f'Root Mean Squared Error: {rmse}')\nprint(f'R-squared: {r2}')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T11:39:19.939020Z","iopub.execute_input":"2024-03-28T11:39:19.939576Z","iopub.status.idle":"2024-03-28T11:46:15.978943Z","shell.execute_reply.started":"2024-03-28T11:39:19.939534Z","shell.execute_reply":"2024-03-28T11:46:15.977057Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 644.2958 - val_loss: 429.4688\nEpoch 2/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 432.7545 - val_loss: 346.4506\nEpoch 3/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 376.0605 - val_loss: 326.5144\nEpoch 4/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 312.1759 - val_loss: 267.8470\nEpoch 5/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 297.3348 - val_loss: 268.2225\nEpoch 6/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 286.1072 - val_loss: 254.1803\nEpoch 7/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 265.7949 - val_loss: 286.3222\nEpoch 8/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 256.6211 - val_loss: 326.2411\nEpoch 9/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 271.5523 - val_loss: 490.7379\nEpoch 10/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 274.2224 - val_loss: 368.2037\nEpoch 11/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 268.1797 - val_loss: 288.4780\nEpoch 12/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 263.9947 - val_loss: 234.6732\nEpoch 13/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 248.4773 - val_loss: 232.1720\nEpoch 14/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 245.1367 - val_loss: 245.5968\nEpoch 15/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 257.1398 - val_loss: 319.7880\nEpoch 16/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 238.4114 - val_loss: 235.1665\nEpoch 17/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 250.9344 - val_loss: 378.7398\nEpoch 18/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 244.8582 - val_loss: 224.0985\nEpoch 19/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 231.3474 - val_loss: 203.5810\nEpoch 20/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 218.4347 - val_loss: 273.3192\nEpoch 21/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 207.2896 - val_loss: 195.5989\nEpoch 22/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 189.1355 - val_loss: 193.9969\nEpoch 23/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 189.0067 - val_loss: 177.8287\nEpoch 24/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 184.3283 - val_loss: 205.1164\nEpoch 25/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 178.5254 - val_loss: 218.8770\nEpoch 26/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 184.4344 - val_loss: 190.9936\nEpoch 27/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 183.1766 - val_loss: 178.7934\nEpoch 28/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 174.4739 - val_loss: 169.7827\nEpoch 29/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 179.2908 - val_loss: 182.0548\nEpoch 30/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 182.4828 - val_loss: 180.1631\nEpoch 31/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 175.0087 - val_loss: 178.4670\nEpoch 32/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 170.0413 - val_loss: 220.2240\nEpoch 33/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 177.8679 - val_loss: 172.5399\nEpoch 34/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 173.8666 - val_loss: 182.8914\nEpoch 35/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 173.7389 - val_loss: 165.3443\nEpoch 36/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 172.1978 - val_loss: 168.3075\nEpoch 37/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 174.9452 - val_loss: 177.4592\nEpoch 38/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 167.9216 - val_loss: 179.7652\nEpoch 39/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 167.5190 - val_loss: 166.6835\nEpoch 40/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 162.3001 - val_loss: 160.7260\nEpoch 41/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 168.7924 - val_loss: 161.4758\nEpoch 42/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 164.7747 - val_loss: 178.1693\nEpoch 43/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 159.3772 - val_loss: 151.9631\nEpoch 44/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 156.8251 - val_loss: 149.2001\nEpoch 45/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 155.1103 - val_loss: 149.4202\nEpoch 46/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 151.2238 - val_loss: 152.9339\nEpoch 47/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 151.3302 - val_loss: 144.9144\nEpoch 48/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 151.9714 - val_loss: 146.8583\nEpoch 49/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 154.5134 - val_loss: 153.7990\nEpoch 50/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 148.7437 - val_loss: 165.3069\nEpoch 51/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 143.1396 - val_loss: 151.3059\nEpoch 52/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 153.2346 - val_loss: 145.4665\nEpoch 53/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 150.6266 - val_loss: 140.6833\nEpoch 54/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 141.5238 - val_loss: 145.9391\nEpoch 55/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 143.9393 - val_loss: 142.0649\nEpoch 56/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 147.0659 - val_loss: 138.8814\nEpoch 57/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 141.2611 - val_loss: 163.0778\nEpoch 58/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 143.0951 - val_loss: 140.7614\nEpoch 59/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 140.0089 - val_loss: 173.2655\nEpoch 60/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 139.8433 - val_loss: 141.0957\nEpoch 61/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 138.4457 - val_loss: 157.1944\nEpoch 62/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 141.8482 - val_loss: 151.7160\nEpoch 63/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.9325 - val_loss: 137.3266\nEpoch 64/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 142.0972 - val_loss: 140.6401\nEpoch 65/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 143.1940 - val_loss: 150.1027\nEpoch 66/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.5703 - val_loss: 136.3446\nEpoch 67/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 141.1623 - val_loss: 139.2420\nEpoch 68/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 140.0543 - val_loss: 143.0620\nEpoch 69/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 137.7377 - val_loss: 135.3741\nEpoch 70/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 142.1542 - val_loss: 140.8181\nEpoch 71/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 139.2606 - val_loss: 143.0981\nEpoch 72/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 141.5507 - val_loss: 131.2121\nEpoch 73/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 139.3751 - val_loss: 135.7521\nEpoch 74/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 138.5669 - val_loss: 131.6764\nEpoch 75/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 133.2976 - val_loss: 132.7986\nEpoch 76/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 133.9886 - val_loss: 129.1468\nEpoch 77/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 132.3551 - val_loss: 131.4992\nEpoch 78/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 133.7683 - val_loss: 132.9964\nEpoch 79/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 131.8287 - val_loss: 129.9369\nEpoch 80/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 133.3472 - val_loss: 130.5110\nEpoch 81/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 134.0477 - val_loss: 141.9193\nEpoch 82/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 132.8619 - val_loss: 128.0578\nEpoch 83/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 135.2374 - val_loss: 142.5065\nEpoch 84/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 132.9495 - val_loss: 131.5038\nEpoch 85/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 132.3442 - val_loss: 139.7027\nEpoch 86/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 133.1590 - val_loss: 138.3630\nEpoch 87/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 134.8520 - val_loss: 132.8274\nEpoch 88/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 132.4518 - val_loss: 130.7958\nEpoch 89/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 130.0180 - val_loss: 138.3782\nEpoch 90/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 135.0798 - val_loss: 130.4573\nEpoch 91/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 132.3784 - val_loss: 127.6322\nEpoch 92/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 129.0575 - val_loss: 130.4646\nEpoch 93/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 134.6314 - val_loss: 137.6827\nEpoch 94/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 130.9812 - val_loss: 129.7010\nEpoch 95/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 128.0441 - val_loss: 131.8100\nEpoch 96/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 133.3948 - val_loss: 130.0182\nEpoch 97/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 131.7174 - val_loss: 129.1478\nEpoch 98/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 128.2923 - val_loss: 131.4498\nEpoch 99/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 134.1003 - val_loss: 129.6253\nEpoch 100/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 130.6837 - val_loss: 127.3056\nEpoch 101/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 129.4682 - val_loss: 132.3412\nEpoch 102/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 128.5773 - val_loss: 128.4775\nEpoch 103/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 128.1274 - val_loss: 130.2475\nEpoch 104/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 129.6581 - val_loss: 137.4786\nEpoch 105/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 133.7666 - val_loss: 135.3235\nEpoch 106/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 135.2072 - val_loss: 135.3009\nEpoch 107/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 130.6449 - val_loss: 129.6407\nEpoch 108/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 138.1857 - val_loss: 130.6035\nEpoch 109/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 131.2599 - val_loss: 130.5557\nEpoch 110/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 132.3795 - val_loss: 139.9323\nEpoch 111/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 133.5237 - val_loss: 135.3714\nEpoch 112/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 131.4021 - val_loss: 134.4910\nEpoch 113/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 129.2126 - val_loss: 130.4491\nEpoch 114/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 129.9404 - val_loss: 134.1408\nEpoch 115/200\n\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 130.5413 - val_loss: 129.1091\n\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nMean Absolute Error: 7.3615893334744875\nMean Squared Error: 117.2230984753638\nRoot Mean Squared Error: 10.826961645603248\nR-squared: 0.7123689485475229\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}