{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"0c044dd9-293a-4185-9ae6-6b8e89b4b943","_uuid":"9779523e-d5d6-41f0-a337-018ba58069b8","collapsed":false,"execution":{"iopub.execute_input":"2024-04-24T12:52:38.790794Z","iopub.status.busy":"2024-04-24T12:52:38.790220Z","iopub.status.idle":"2024-04-24T12:56:16.585047Z","shell.execute_reply":"2024-04-24T12:56:16.583711Z","shell.execute_reply.started":"2024-04-24T12:52:38.790758Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:384: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"]},{"name":"stdout","output_type":"stream","text":["| epoch   1 |   767/ 3839 batches | lr 0.005000 |  4.85 ms | loss 0.17508 | ppl     1.19\n","| epoch   1 |  1534/ 3839 batches | lr 0.005000 |  4.81 ms | loss 0.20081 | ppl     1.22\n","| epoch   1 |  2301/ 3839 batches | lr 0.005000 |  4.80 ms | loss 0.03487 | ppl     1.04\n","| epoch   1 |  3068/ 3839 batches | lr 0.005000 |  4.82 ms | loss 0.05781 | ppl     1.06\n","| epoch   1 |  3835/ 3839 batches | lr 0.005000 |  4.78 ms | loss 0.06084 | ppl     1.06\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 19.58s | valid loss 0.07597 | valid ppl     1.08\n","-----------------------------------------------------------------------------------------\n","| epoch   2 |   767/ 3839 batches | lr 0.004513 |  4.79 ms | loss 0.11239 | ppl     1.12\n","| epoch   2 |  1534/ 3839 batches | lr 0.004513 |  4.72 ms | loss 0.20370 | ppl     1.23\n","| epoch   2 |  2301/ 3839 batches | lr 0.004513 |  4.72 ms | loss 0.03469 | ppl     1.04\n","| epoch   2 |  3068/ 3839 batches | lr 0.004513 |  4.73 ms | loss 0.05478 | ppl     1.06\n","| epoch   2 |  3835/ 3839 batches | lr 0.004513 |  4.69 ms | loss 0.06037 | ppl     1.06\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 19.21s | valid loss 0.08039 | valid ppl     1.08\n","-----------------------------------------------------------------------------------------\n","| epoch   3 |   767/ 3839 batches | lr 0.004287 |  4.68 ms | loss 0.11226 | ppl     1.12\n","| epoch   3 |  1534/ 3839 batches | lr 0.004287 |  4.67 ms | loss 0.16521 | ppl     1.18\n","| epoch   3 |  2301/ 3839 batches | lr 0.004287 |  4.61 ms | loss 0.03362 | ppl     1.03\n","| epoch   3 |  3068/ 3839 batches | lr 0.004287 |  4.64 ms | loss 0.03689 | ppl     1.04\n","| epoch   3 |  3835/ 3839 batches | lr 0.004287 |  4.65 ms | loss 0.03724 | ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 18.91s | valid loss 0.03865 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch   4 |   767/ 3839 batches | lr 0.004073 |  4.61 ms | loss 0.04272 | ppl     1.04\n","| epoch   4 |  1534/ 3839 batches | lr 0.004073 |  4.64 ms | loss 0.06428 | ppl     1.07\n","| epoch   4 |  2301/ 3839 batches | lr 0.004073 |  4.61 ms | loss 0.02621 | ppl     1.03\n","| epoch   4 |  3068/ 3839 batches | lr 0.004073 |  4.72 ms | loss 0.02880 | ppl     1.03\n","| epoch   4 |  3835/ 3839 batches | lr 0.004073 |  4.68 ms | loss 0.03611 | ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 18.92s | valid loss 0.03815 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch   5 |   767/ 3839 batches | lr 0.003869 |  4.68 ms | loss 0.04163 | ppl     1.04\n","| epoch   5 |  1534/ 3839 batches | lr 0.003869 |  4.68 ms | loss 0.06255 | ppl     1.06\n","| epoch   5 |  2301/ 3839 batches | lr 0.003869 |  4.66 ms | loss 0.02470 | ppl     1.03\n","| epoch   5 |  3068/ 3839 batches | lr 0.003869 |  4.71 ms | loss 0.02809 | ppl     1.03\n","| epoch   5 |  3835/ 3839 batches | lr 0.003869 |  4.70 ms | loss 0.03541 | ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 29.25s | valid loss 0.03671 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch   6 |   767/ 3839 batches | lr 0.003675 |  4.78 ms | loss 0.04141 | ppl     1.04\n","| epoch   6 |  1534/ 3839 batches | lr 0.003675 |  4.70 ms | loss 0.06233 | ppl     1.06\n","| epoch   6 |  2301/ 3839 batches | lr 0.003675 |  4.69 ms | loss 0.02426 | ppl     1.02\n","| epoch   6 |  3068/ 3839 batches | lr 0.003675 |  4.68 ms | loss 0.02753 | ppl     1.03\n","| epoch   6 |  3835/ 3839 batches | lr 0.003675 |  4.72 ms | loss 0.03513 | ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 19.20s | valid loss 0.03540 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch   7 |   767/ 3839 batches | lr 0.003492 |  4.72 ms | loss 0.04096 | ppl     1.04\n","| epoch   7 |  1534/ 3839 batches | lr 0.003492 |  4.77 ms | loss 0.06128 | ppl     1.06\n","| epoch   7 |  2301/ 3839 batches | lr 0.003492 |  4.75 ms | loss 0.02505 | ppl     1.03\n","| epoch   7 |  3068/ 3839 batches | lr 0.003492 |  4.71 ms | loss 0.02744 | ppl     1.03\n","| epoch   7 |  3835/ 3839 batches | lr 0.003492 |  4.69 ms | loss 0.03474 | ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 19.22s | valid loss 0.03619 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch   8 |   767/ 3839 batches | lr 0.003317 |  4.70 ms | loss 0.03996 | ppl     1.04\n","| epoch   8 |  1534/ 3839 batches | lr 0.003317 |  4.64 ms | loss 0.06002 | ppl     1.06\n","| epoch   8 |  2301/ 3839 batches | lr 0.003317 |  4.63 ms | loss 0.02418 | ppl     1.02\n","| epoch   8 |  3068/ 3839 batches | lr 0.003317 |  4.65 ms | loss 0.02701 | ppl     1.03\n","| epoch   8 |  3835/ 3839 batches | lr 0.003317 |  4.61 ms | loss 0.03429 | ppl     1.03\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 18.91s | valid loss 0.03537 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch   9 |   767/ 3839 batches | lr 0.003151 |  4.73 ms | loss 0.03934 | ppl     1.04\n","| epoch   9 |  1534/ 3839 batches | lr 0.003151 |  4.64 ms | loss 0.05897 | ppl     1.06\n","| epoch   9 |  2301/ 3839 batches | lr 0.003151 |  4.66 ms | loss 0.02576 | ppl     1.03\n","| epoch   9 |  3068/ 3839 batches | lr 0.003151 |  4.65 ms | loss 0.02677 | ppl     1.03\n","| epoch   9 |  3835/ 3839 batches | lr 0.003151 |  4.62 ms | loss 0.03411 | ppl     1.03\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 18.95s | valid loss 0.03543 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n","| epoch  10 |   767/ 3839 batches | lr 0.002994 |  4.68 ms | loss 0.03833 | ppl     1.04\n","| epoch  10 |  1534/ 3839 batches | lr 0.002994 |  4.67 ms | loss 0.05633 | ppl     1.06\n","| epoch  10 |  2301/ 3839 batches | lr 0.002994 |  4.66 ms | loss 0.02462 | ppl     1.02\n","| epoch  10 |  3068/ 3839 batches | lr 0.002994 |  4.68 ms | loss 0.02670 | ppl     1.03\n","| epoch  10 |  3835/ 3839 batches | lr 0.002994 |  4.63 ms | loss 0.03369 | ppl     1.03\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 29.33s | valid loss 0.03536 | valid ppl     1.04\n","-----------------------------------------------------------------------------------------\n"]}],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import time\n","import math\n","from matplotlib import pyplot\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","torch.manual_seed(0)\n","np.random.seed(0)\n","\n","\n","input_window = 100 \n","output_window = 1 \n","block_len = input_window + output_window \n","batch_size = 10\n","train_size = 0.8\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()       \n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = 1 / (10000 ** ((2 * np.arange(d_model)) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term[0::2])\n","        pe[:, 1::2] = torch.cos(position * div_term[1::2])\n","\n","        pe = pe.unsqueeze(0).transpose(0, 1) \n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0), :].repeat(1,x.shape[1],1)\n","          \n","\n","class JV2former(nn.Module):\n","    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n","        super(JV2former, self).__init__()\n","        self.model_type = 'Transformer'\n","        self.input_embedding  = nn.Linear(1,feature_size)\n","        self.src_mask = None\n","\n","        self.pos_encoder = PositionalEncoding(feature_size)\n","        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n","        self.decoder = nn.Linear(feature_size,1)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.1    \n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self,src):\n","        if self.src_mask is None or self.src_mask.size(0) != len(src):\n","            device = src.device\n","            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n","            self.src_mask = mask\n","\n","        src = self.input_embedding(src) \n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src,self.src_mask)\n","        output = self.decoder(output)\n","        return output\n","\n","    def _generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","def create_inout_sequences(input_data, input_window ,output_window):\n","    inout_seq = []\n","    L = len(input_data)\n","    block_num =  L - block_len + 1\n","\n","    for i in range( block_num ):\n","        train_seq = input_data[i : i + input_window]\n","        train_label = input_data[i + output_window : i + input_window + output_window]\n","        inout_seq.append((train_seq ,train_label))\n","\n","    return torch.FloatTensor(np.array(inout_seq))\n","\n","def get_data(csv_file, train_size, input_window, output_window, device):\n","    data = pd.read_csv(csv_file)\n","\n","    data['DateTime'] = pd.to_datetime(data['DateTime'])\n","\n","    scaler = MinMaxScaler(feature_range=(-1, 1)) \n","    data['Vehicles'] = scaler.fit_transform(data['Vehicles'].values.reshape(-1, 1)).reshape(-1)\n","\n","    sampels = int(len(data) * train_size)\n","    train_data = data['Vehicles'][:sampels]\n","    test_data = data['Vehicles'][sampels:]\n","\n","    train_sequence = create_inout_sequences(train_data, input_window, output_window)\n","    test_sequence = create_inout_sequences(test_data, input_window, output_window)\n","\n","    train_sequence = torch.FloatTensor(train_sequence).to(device)\n","    test_sequence = torch.FloatTensor(test_sequence).to(device)\n","\n","    return train_sequence, test_sequence\n","\n","\n","def get_batch(input_data, i , batch_size):\n","\n","    batch_len = min(batch_size, len(input_data) - i)\n","    data = input_data[ i:i + batch_len ]\n","    input = torch.stack([item[0] for item in data]).view((input_window,batch_len,1))\n","    target = torch.stack([item[1] for item in data]).view((input_window,batch_len,1))\n","    return input, target\n","\n","def train(train_data):\n","    model.train() \n","    total_loss = 0.\n","    start_time = time.time()\n","\n","    for batch, i in enumerate(range(0, len(train_data), batch_size)):\n","        data, targets = get_batch(train_data, i , batch_size)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        log_interval = int(len(train_data) / batch_size / 5)\n","        if batch % log_interval == 0 and batch > 0:\n","            cur_loss = total_loss / log_interval\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n","                  'lr {:02.6f} | {:5.2f} ms | '\n","                  'loss {:5.5f} | ppl {:8.2f}'.format(\n","                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n","                    elapsed * 1000 / log_interval,\n","                    cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def plot_and_loss(eval_model, data_source,epoch):\n","    eval_model.eval() \n","    total_loss = 0.\n","    test_result = torch.Tensor(0)    \n","    truth = torch.Tensor(0)\n","    with torch.no_grad():\n","        for i in range(len(data_source)):  \n","            data, target = get_batch(data_source, i , 1) \n","            output = eval_model(data)            \n","            total_loss += criterion(output, target).item()\n","            test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0)\n","            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n","            \n","    len(test_result)\n","\n","    pyplot.plot(test_result,color=\"red\")\n","    pyplot.plot(truth[:500],color=\"blue\")\n","    pyplot.plot(test_result-truth,color=\"green\")\n","    pyplot.grid(True, which='both')\n","    pyplot.axhline(y=0, color='k')\n","    pyplot.close()\n","    return total_loss / i\n","\n"," \n","def predict_future(eval_model, data_source,steps):\n","    eval_model.eval() \n","    total_loss = 0.\n","    test_result = torch.Tensor(0)    \n","    truth = torch.Tensor(0)\n","    data, _ = get_batch(data_source , 0 , 1)\n","    with torch.no_grad():\n","        for i in range(0, steps):            \n","            output = eval_model(data[-input_window:])\n","\n","            data = torch.cat((data, output[-1:])) \n","\n","    data = data.cpu().view(-1)\n","\n","    pyplot.plot(data,color=\"red\")       \n","    pyplot.plot(data[:input_window],color=\"blue\")    \n","    pyplot.grid(True, which='both')\n","    pyplot.axhline(y=0, color='k')\n","\n","    pyplot.show()\n","    pyplot.close()\n","        \n","\n","def evaluate(eval_model, data_source):\n","    eval_model.eval() \n","    total_loss = 0.\n","    eval_batch_size = 1000\n","    with torch.no_grad():\n","        for i in range(0, len(data_source), eval_batch_size):\n","            data, targets = get_batch(data_source, i,eval_batch_size)\n","            output = eval_model(data)            \n","            total_loss += len(data[0]) * criterion(output, targets).cpu().item()\n","    return total_loss / len(data_source)\n","\n","train_data, val_data = get_data(\"/kaggle/input/vehicle-count/traffic.csv\", train_size, input_window, output_window, device)\n","model = JV2former().to(device)\n","\n","criterion = nn.L1Loss()\n","lr = 0.005 \n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95)\n","\n","best_val_loss = float(\"inf\")\n","epochs = 10 \n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train(train_data)\n","    if ( epoch % 5 == 0 ):\n","        val_loss = plot_and_loss(model, val_data,epoch)\n","\n","    else:\n","        val_loss = evaluate(model, val_data)\n","   \n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","                                     val_loss, math.exp(val_loss)))\n","    print('-' * 89)\n","\n","\n","    scheduler.step() \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4591720,"sourceId":7834045,"sourceType":"datasetVersion"},{"datasetId":4845206,"sourceId":8183278,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
